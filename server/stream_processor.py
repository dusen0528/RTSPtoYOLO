"""
ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ - YOLO ì–¼êµ´ ê°ì§€ + ë¸”ëŸ¬ ì²˜ë¦¬ + FFmpeg RTSP ì¶œë ¥
"""
import cv2
import numpy as np
import subprocess
import threading
import time
from collections import deque
from typing import Optional, Tuple
from datetime import datetime
import psutil
import os
import select

from .models import BlurSettings, StreamStatus
from .config import settings


class FaceTracker:
    """ì–¼êµ´ ìœ„ì¹˜ ì¶”ì  (ë¸”ëŸ¬ ì•ˆì •í™”)"""
    
    def __init__(self, max_age: int = 25, smoothing: float = 0.5):
        self.tracks = {}
        self.next_id = 0
        self.max_age = max_age
        self.smoothing = smoothing
    
    def update(self, detections: list) -> list:
        """ìƒˆ ê°ì§€ ê²°ê³¼ë¡œ íŠ¸ë™ ì—…ë°ì´íŠ¸"""
        # ëª¨ë“  íŠ¸ë™ì˜ age ì¦ê°€
        for track_id in list(self.tracks.keys()):
            self.tracks[track_id]['age'] += 1
            if self.tracks[track_id]['age'] > self.max_age:
                del self.tracks[track_id]
        
        # ìƒˆ ê°ì§€ì™€ ê¸°ì¡´ íŠ¸ë™ ë§¤ì¹­
        used_tracks = set()
        for det in detections:
            best_iou = 0
            best_track_id = None
            
            for track_id, track in self.tracks.items():
                if track_id in used_tracks:
                    continue
                iou = self._calc_iou(det, track['box'])
                if iou > best_iou and iou > 0.3:
                    best_iou = iou
                    best_track_id = track_id
            
            if best_track_id is not None:
                old_box = self.tracks[best_track_id]['box']
                new_box = [
                    int(old_box[i] * self.smoothing + det[i] * (1 - self.smoothing))
                    for i in range(4)
                ]
                self.tracks[best_track_id] = {'box': new_box, 'age': 0}
                used_tracks.add(best_track_id)
            else:
                self.tracks[self.next_id] = {'box': list(det), 'age': 0}
                self.next_id += 1
        
        return [track['box'] for track in self.tracks.values()]
    
    def _calc_iou(self, box1, box2) -> float:
        """IoU ê³„ì‚°"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])
        
        inter = max(0, x2 - x1) * max(0, y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - inter
        
        return inter / union if union > 0 else 0
    
    def reset(self):
        """íŠ¸ë˜ì»¤ ì´ˆê¸°í™”"""
        self.tracks = {}
        self.next_id = 0


class StreamProcessor:
    """RTSP ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ê¸°"""
    
    def __init__(
        self,
        stream_id: str,
        input_url: str,
        output_url: str,
        model,  # YOLO ëª¨ë¸ (ê³µìœ )
        model_lock: threading.Lock,  # ì¶”ë¡  ë½ (ìŠ¤ë ˆë“œ ì•ˆì „ì„±)
        blur_settings: BlurSettings
    ):
        self.stream_id = stream_id
        self.input_url = input_url
        self.output_url = output_url
        self.model = model
        self.model_lock = model_lock
        self.blur_settings = blur_settings
        
        # ìƒíƒœ
        self.status = StreamStatus.PENDING
        self.error_message: Optional[str] = None
        self.started_at: Optional[datetime] = None
        
        # í†µê³„
        self.frame_count = 0
        self.frames_skipped = 0  # ìŠ¤í‚µëœ í”„ë ˆì„ ìˆ˜
        self.faces_detected = 0
        self.fps = 0.0
        self.cpu_usage = 0.0
        self.inference_time_ms = 0.0
        
        # ë‚´ë¶€
        self._thread: Optional[threading.Thread] = None
        self._stop_event = threading.Event()
        self._cap: Optional[cv2.VideoCapture] = None
        self._ffmpeg_process: Optional[subprocess.Popen] = None
        self._tracker = FaceTracker(
            max_age=blur_settings.max_age,
            smoothing=blur_settings.smoothing
        )
        
        # FFmpeg ì—ëŸ¬ ë©”ì‹œì§€ ì €ì¥ìš©
        self._ffmpeg_stderr = None
        
        # FPS ê³„ì‚°ìš©
        self._fps_times = deque(maxlen=30)
        self._inference_times = deque(maxlen=30)
        
        # ë¶€í•˜ ì œì–´ìš©
        self._min_frame_interval = 1.0 / settings.max_fps  # FPS ì œí•œ
        self._last_frame_time = 0.0
        self._last_boxes = []  # ë§ˆì§€ë§‰ ê°ì§€ ë°•ìŠ¤ (í”„ë ˆì„ ìŠ¤í‚µ ì‹œ ì¬ì‚¬ìš©)
        
        # í”„ë ˆì„ ìŠ¤í‚µ ì œì–´
        self._frame_index = 0  # í”„ë ˆì„ ì¸ë±ìŠ¤ (frame_skip_ratio ì œì–´ìš©)
    
    def start(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œì‘ (STARTING ìƒíƒœë¡œ ì „í™˜, ì„±ê³µ í›„ RUNNING)"""
        if self.status == StreamStatus.RUNNING or self.status == StreamStatus.STARTING:
            return
        
        self._stop_event.clear()
        self.error_message = None
        self.status = StreamStatus.STARTING  # ì‹œì‘ ì¤‘ ìƒíƒœ
        self.started_at = datetime.now()
        
        self._thread = threading.Thread(target=self._process_loop, daemon=True)
        self._thread.start()
    
    def stop(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ì§€ (ë¹ ë¥¸ ì¢…ë£Œ + ê°•ì œ ì •ë¦¬)"""
        if self.status == StreamStatus.STOPPED:
            return
        
        print(f"[{self.stream_id}] ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ìš”ì²­...")
        self._stop_event.set()
        
        # 1. FFmpeg stdin ì¦‰ì‹œ ë‹«ê¸° (ë¸”ë¡œí‚¹ ë°©ì§€)
        if self._ffmpeg_process and self._ffmpeg_process.stdin:
            try:
                self._ffmpeg_process.stdin.close()
            except:
                pass
        
        # 2. VideoCapture ê°•ì œ í•´ì œ (read() ë¸”ë¡œí‚¹ íƒˆì¶œ) - ì¦‰ì‹œ í•´ì œ
        if self._cap is not None:
            try:
                self._cap.release()
            except Exception as e:
                print(f"[{self.stream_id}] VideoCapture í•´ì œ ì˜¤ë¥˜: {e}")
            finally:
                self._cap = None  # ì¦‰ì‹œ Noneìœ¼ë¡œ ì„¤ì •
        
        # 3. FFmpeg í”„ë¡œì„¸ìŠ¤ ì¦‰ì‹œ ê°•ì œ ì¢…ë£Œ (terminate ëŒ€ì‹  kill ìš°ì„ )
        if self._ffmpeg_process:
            try:
                # stdinì´ ì´ë¯¸ ë‹«í˜”ìœ¼ë¯€ë¡œ killë¡œ ì¦‰ì‹œ ì¢…ë£Œ
                self._ffmpeg_process.kill()
            except:
                pass
        
        # 4. ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ 0.5ì´ˆë¡œ ë‹¨ì¶•)
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=0.5)
            
            # ìŠ¤ë ˆë“œê°€ ì—¬ì „íˆ ì‚´ì•„ìˆìœ¼ë©´ ê°•ì œ ì •ë¦¬
            if self._thread.is_alive():
                print(f"[{self.stream_id}] âš ï¸ ìŠ¤ë ˆë“œê°€ íƒ€ì„ì•„ì›ƒ ë‚´ ì¢…ë£Œë˜ì§€ ì•ŠìŒ, ê°•ì œ ì •ë¦¬...")
        
        # 5. ìµœì¢… ì •ë¦¬ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ì—¬ ë¹ ë¥¸ ë°˜í™˜)
        self._cleanup_fast()
        self.status = StreamStatus.STOPPED
        print(f"[{self.stream_id}] ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ì™„ë£Œ")
    
    def update_settings(self, blur_settings: BlurSettings):
        """ë¸”ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.blur_settings = blur_settings
        self._tracker = FaceTracker(
            max_age=blur_settings.max_age,
            smoothing=blur_settings.smoothing
        )
    
    def get_stats(self) -> dict:
        """í˜„ì¬ í†µê³„ ë°˜í™˜"""
        uptime = 0.0
        if self.started_at:
            uptime = (datetime.now() - self.started_at).total_seconds()
        
        return {
            'fps': self.fps,
            'frame_count': self.frame_count,
            'faces_detected': self.faces_detected,
            'cpu_usage': self.cpu_usage,
            'inference_time_ms': self.inference_time_ms,
            'uptime_seconds': uptime,
        }
    
    def _process_loop(self):
        """ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ (ë¶€í•˜ ì œì–´ + ì•ˆì •ì„± ê°•í™”)"""
        first_frame_success = False
        
        try:
            # ëª¨ë¸ ì²´í¬
            if self.model is None:
                raise Exception("YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì—°ê²° (ì§€ì—° ìµœì†Œí™”)
            print(f"[{self.stream_id}] RTSP ì—°ê²° ì¤‘: {self.input_url[:50]}...")
            
            # RTSP ì €ì§€ì—° ì˜µì…˜ì„ os.environìœ¼ë¡œ ì„¤ì • (OpenCV FFmpegì´ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡)
            # rw_timeout ë‹¨ì¶•: read()ê°€ 0.5ì´ˆ ë‚´ì— ë°˜í™˜í•˜ì—¬ stop ì´ë²¤íŠ¸ ë¹ ë¥´ê²Œ í™•ì¸ ê°€ëŠ¥
            os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = (
                "rtsp_transport;tcp|"
                "fflags;nobuffer|"
                "flags;low_delay|"
                "max_delay;0|"
                "reorder_queue_size;0|"
                "stimeout;500000|"  # 0.5ì´ˆë¡œ ë‹¨ì¶•
                "rw_timeout;500000"  # 0.5ì´ˆë¡œ ë‹¨ì¶• (stop ì‹œ ë¹ ë¥¸ ë°˜í™˜)
            )
            
            self._cap = cv2.VideoCapture(self.input_url, cv2.CAP_FFMPEG)
            self._cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            if not self._cap.isOpened():
                raise Exception(f"ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì‹¤íŒ¨: {self.input_url}")
            
            # í”„ë ˆì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            width = int(self._cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self._cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            if width == 0 or height == 0:
                width, height = 1920, 1080  # ê¸°ë³¸ê°’
            
            # ì¶œë ¥ í•´ìƒë„ ê³„ì‚° (ë‹¤ìš´ìŠ¤ì¼€ì¼)
            out_width = int(width * settings.output_scale)
            out_height = int(height * settings.output_scale)
            
            # FFmpeg ì¶œë ¥ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
            self._start_ffmpeg(out_width, out_height)
            
            # FFmpeg ì‹œì‘ í™•ì¸ (ì¡°ê¸ˆ ë” ê¸°ë‹¤ë ¤ì„œ ì—°ê²° ì‹œë„ í™•ì¸)
            time.sleep(1.0)  # 0.5ì´ˆ â†’ 1ì´ˆë¡œ ì¦ê°€ (ì—°ê²° ì‹œë„ ì‹œê°„ í™•ë³´)
            if not self._check_ffmpeg_alive():
                error_msg = self._get_ffmpeg_error()
                # ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ìƒì„¸ ì¶œë ¥
                if error_msg:
                    print(f"[{self.stream_id}] âŒ FFmpeg ì—°ê²° ì‹¤íŒ¨ ìƒì„¸:")
                    for line in error_msg.split('\n')[:10]:  # ìµœëŒ€ 10ì¤„ë§Œ
                        if line.strip():
                            print(f"[{self.stream_id}]    {line}")
                raise Exception(f"FFmpeg ì‹œì‘ ì‹¤íŒ¨: {self.output_url}. {error_msg if error_msg else 'ì—ëŸ¬ ë©”ì‹œì§€ ì—†ìŒ'}")
            else:
                print(f"[{self.stream_id}] âœ… FFmpeg ì—°ê²° ì„±ê³µ: {self.output_url}")
            
            process = psutil.Process()
            reconnect_count = 0
            max_reconnect = 5
            
            while not self._stop_event.is_set():
                current_time = time.time()
                
                # ì¤‘ì§€ ì²´í¬ (read() ì „)
                if self._stop_event.is_set():
                    break
                
                # VideoCaptureê°€ Noneì´ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                if self._cap is None:
                    break
                
                ret, frame = self._cap.read()
                
                # ì¤‘ì§€ ì²´í¬ (read() í›„ ì¦‰ì‹œ)
                if self._stop_event.is_set() or self._cap is None:
                    break
                
                if not ret or frame is None:
                    # ì¤‘ì§€ ì²´í¬ (read() ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ í™•ì¸)
                    if self._stop_event.is_set():
                        break
                    
                    reconnect_count += 1
                    if reconnect_count > max_reconnect:
                        raise Exception(f"RTSP ì¬ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {max_reconnect}íšŒ)")
                    
                    print(f"[{self.stream_id}] ì¬ì—°ê²° ì‹œë„ {reconnect_count}/{max_reconnect}...")
                    
                    # ì¤‘ì§€ ì²´í¬ (ì¬ì—°ê²° ëŒ€ê¸° ì¤‘)
                    if self._stop_event.wait(timeout=1):
                        break
                    
                    # ì¤‘ì§€ ì²´í¬ (ì¬ì—°ê²° ì „)
                    if self._stop_event.is_set():
                        break
                    
                    # ì¬ì—°ê²° ì‹œì—ë„ RTSP ì €ì§€ì—° ì˜µì…˜ ì ìš© (os.environì€ ì´ë¯¸ ì„¤ì •ë¨)
                    try:
                        self._cap.release()
                    except:
                        pass
                    self._cap = cv2.VideoCapture(self.input_url, cv2.CAP_FFMPEG)
                    self._cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    continue
                
                reconnect_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ë¦¬ì…‹
                
                # ì²« í”„ë ˆì„ ì„±ê³µ â†’ RUNNING ìƒíƒœë¡œ ì „í™˜
                if not first_frame_success:
                    first_frame_success = True
                    self.status = StreamStatus.RUNNING
                    print(f"[{self.stream_id}] ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì„±ê³µ! ({width}x{height})")
                
                # frame_skip_ratioë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ ë“œë¡­
                self._frame_index += 1
                should_process_frame = (self._frame_index % settings.frame_skip_ratio == 0)
                
                if not should_process_frame:
                    # í”„ë ˆì„ ìŠ¤í‚µ: ì´ì „ ë°•ìŠ¤ë¡œ ë¸”ëŸ¬ë§Œ ì ìš©í•˜ê³  ì „ì†¡/ì¸ì½”ë”© ìì²´ë¥¼ ê±´ë„ˆëœ€
                    self.frames_skipped += 1
                    stable_boxes = self._last_boxes
                    # ì¸ì½”ë”©/ì „ì†¡ë„ ê±´ë„ˆë›°ë¯€ë¡œ continue
                    # ì¤‘ì§€ ì²´í¬
                    if self._stop_event.is_set():
                        break
                    continue
                
                # ì¤‘ì§€ ì²´í¬ (ì²˜ë¦¬ ì „)
                if self._stop_event.is_set():
                    break
                
                # FPS ì œí•œ: ë„ˆë¬´ ë¹ ë¥´ë©´ í”„ë ˆì„ ìŠ¤í‚µ
                time_since_last = current_time - self._last_frame_time
                should_skip = settings.enable_frame_skip and time_since_last < self._min_frame_interval
                
                if should_skip:
                    # í”„ë ˆì„ ìŠ¤í‚µ: ì´ì „ ë°•ìŠ¤ë¡œ ë¸”ëŸ¬ë§Œ ì ìš©
                    self.frames_skipped += 1
                    stable_boxes = self._last_boxes
                else:
                    # YOLO ì¶”ë¡  (ë½ìœ¼ë¡œ ìŠ¤ë ˆë“œ ì•ˆì „ + íƒ€ì„ì•„ì›ƒ)
                    inference_start = time.time()
                    
                    acquired = self.model_lock.acquire(timeout=settings.inference_timeout)
                    if not acquired:
                        # íƒ€ì„ì•„ì›ƒ: ì´ì „ ë°•ìŠ¤ ì‚¬ìš©
                        print(f"[{self.stream_id}] ì¶”ë¡  íƒ€ì„ì•„ì›ƒ, í”„ë ˆì„ ë“œë¡­")
                        stable_boxes = self._last_boxes
                    else:
                        try:
                            # ì¤‘ì§€ ì²´í¬ (ì¶”ë¡  ì „)
                            if self._stop_event.is_set():
                                stable_boxes = self._last_boxes
                            else:
                                # person ê°ì§€ ëª¨ë“œì¸ ê²½ìš° classes=[0]ìœ¼ë¡œ personë§Œ ê°ì§€
                                model_kwargs = {
                                    'verbose': False,
                                    'imgsz': self.blur_settings.imgsz,
                                    'conf': self.blur_settings.confidence_threshold,
                                    'iou': self.blur_settings.iou_threshold
                                }
                                
                                if settings.use_person_detection:
                                    model_kwargs['classes'] = [0]  # person í´ë˜ìŠ¤ë§Œ (COCO ë°ì´í„°ì…‹ ê¸°ì¤€)
                                
                                results = self.model(frame, **model_kwargs)
                                
                                # ì¤‘ì§€ ì²´í¬ (ì¶”ë¡  í›„)
                                if self._stop_event.is_set():
                                    stable_boxes = self._last_boxes
                                else:
                                    inference_time = time.time() - inference_start
                                    self._inference_times.append(inference_time * 1000)
                                    
                                    # ê°ì§€ëœ ê°ì²´ ì¶”ì¶œ (person ë˜ëŠ” face)
                                    detections = []
                                    h, w = frame.shape[:2]
                                    expand_ratio = self.blur_settings.box_expand_ratio
                                    
                                    for box in results[0].boxes:
                                        # í´ë˜ìŠ¤ í™•ì¸ (person = 0, faceëŠ” ë³„ë„ í´ë˜ìŠ¤)
                                        cls_id = int(box.cls[0].cpu().numpy())
                                        cls_name = results[0].names[cls_id] if hasattr(results[0], 'names') else None
                                        
                                        # person ê°ì§€ ëª¨ë“œì¸ ê²½ìš° person í´ë˜ìŠ¤ë§Œ í•„í„°ë§
                                        if settings.use_person_detection:
                                            # person í´ë˜ìŠ¤ëŠ” ë³´í†µ 0ë²ˆ (COCO ë°ì´í„°ì…‹ ê¸°ì¤€)
                                            if cls_id != 0 and cls_name != 'person':
                                                continue
                                        
                                        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                                        
                                        # ë°•ìŠ¤ í¬ê¸° ê³„ì‚° (í™•ì¥ ì „ ì›ë³¸ í¬ê¸°)
                                        box_width = x2 - x1
                                        box_height = y2 - y1
                                        
                                        # ë°•ìŠ¤ í™•ì¥ ë¹„ìœ¨ì„ ê°€ë¡œ/ì„¸ë¡œ ë¶„ë¦¬ (ê°€ë¡œëŠ” ì‘ê²Œ, ì„¸ë¡œëŠ” ì ë‹¹íˆ)
                                        expand_x_ratio = 0.05  # ê°€ë¡œ í™•ì¥ì€ 5% ì •ë„ë§Œ
                                        expand_y_ratio = 0.08  # ì„¸ë¡œëŠ” 8% ì •ë„
                                        
                                        expand_x = int(box_width * expand_x_ratio)
                                        expand_y = int(box_height * expand_y_ratio)
                                        
                                        # ë°•ìŠ¤ í™•ì¥ ì ìš©
                                        x1 = max(0, x1 - expand_x)
                                        y1 = max(0, y1 - expand_y)
                                        x2 = min(w, x2 + expand_x)
                                        y2 = min(h, y2 + expand_y)
                                        
                                        # ë¨¸ë¦¬ ë¶€ë¶„ë§Œ ìë¥´ê¸°: ìƒë‹¨ 60% ì˜ì—­ë§Œ ì‚¬ìš©
                                        head_ratio = 0.6
                                        new_height = int((y2 - y1) * head_ratio)
                                        y2 = y1 + new_height
                                        
                                        # ì„¸ë¡œ ê¸¸ì´ì— ë§ì¶°ì„œ ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¤ê¸°
                                        height = y2 - y1
                                        center_x = (x1 + x2) // 2
                                        half_size = height // 2
                                        
                                        x1 = max(0, center_x - half_size)
                                        x2 = min(w, center_x + half_size)
                                        
                                        # ì •ì‚¬ê°í˜•ì´ í”„ë ˆì„ì„ ë²—ì–´ë‚˜ë©´ ì¡°ì •
                                        if x2 - x1 < height:
                                            # ê°€ë¡œê°€ ì„¸ë¡œë³´ë‹¤ ì‘ìœ¼ë©´ ì„¸ë¡œë¥¼ ê°€ë¡œì— ë§ì¶¤
                                            if x2 - x1 > 0:
                                                y2 = y1 + (x2 - x1)
                                        
                                        detections.append((x1, y1, x2, y2))
                                    
                                    # íŠ¸ë˜ì»¤ë¡œ ì•ˆì •í™”
                                    stable_boxes = self._tracker.update(detections)
                                    self._last_boxes = stable_boxes  # ë‹¤ìŒ ìŠ¤í‚µìš© ì €ì¥
                                    self._last_frame_time = current_time
                        finally:
                            self.model_lock.release()
                        
                        # ì¤‘ì§€ ì²´í¬ (ë½ í•´ì œ í›„)
                        if self._stop_event.is_set():
                            break
                
                self.faces_detected = len(stable_boxes)
                
                # ë¸”ëŸ¬ ì²˜ë¦¬
                for box in stable_boxes:
                    frame = self._apply_blur(frame, box)
                
                # í•´ìƒë„ ë‹¤ìš´ìŠ¤ì¼€ì¼ (ì„¤ì •ëœ ê²½ìš°)
                if settings.output_scale != 1.0:
                    frame = cv2.resize(frame, (out_width, out_height), interpolation=cv2.INTER_LINEAR)
                
                # ì¤‘ì§€ ì²´í¬
                if self._stop_event.is_set():
                    break
                
                # FFmpegìœ¼ë¡œ ì¶œë ¥ (exit ê°ì‹œ í¬í•¨)
                if not self._check_ffmpeg_alive():
                    if not self._stop_event.is_set():
                        error_msg = self._get_ffmpeg_error()
                        if error_msg:
                            print(f"[{self.stream_id}] FFmpeg ì—ëŸ¬: {error_msg[:300]}")
                        print(f"[{self.stream_id}] FFmpeg ì¢…ë£Œ ê°ì§€, ì¬ì‹œì‘...")
                        self._restart_ffmpeg(out_width, out_height)
                
                # ì¤‘ì§€ ì²´í¬
                if self._stop_event.is_set():
                    break
                
                if self._ffmpeg_process and self._ffmpeg_process.poll() is None:
                    try:
                        if not self._stop_event.is_set():
                            self._ffmpeg_process.stdin.write(frame.tobytes())
                    except (BrokenPipeError, OSError):
                        if not self._stop_event.is_set():
                            self._restart_ffmpeg(out_width, out_height)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.frame_count += 1
                self._fps_times.append(time.time())
                
                if len(self._fps_times) >= 2:
                    elapsed = self._fps_times[-1] - self._fps_times[0]
                    if elapsed > 0:
                        self.fps = len(self._fps_times) / elapsed
                
                if self._inference_times:
                    self.inference_time_ms = sum(self._inference_times) / len(self._inference_times)
                
                # CPU ì‚¬ìš©ë¥  (30í”„ë ˆì„ë§ˆë‹¤, ë…¼ë¸”ë¡œí‚¹)
                if self.frame_count % 30 == 0:
                    try:
                        self.cpu_usage = process.cpu_percent(interval=0) / psutil.cpu_count()
                    except:
                        pass
        
        except Exception as e:
            self.status = StreamStatus.ERROR
            self.error_message = str(e)
            print(f"[{self.stream_id}] ì—ëŸ¬: {e}")
        finally:
            self._cleanup()
            # ì„±ê³µ ëª»í•˜ê³  ì¢…ë£Œë˜ë©´ ERROR ìƒíƒœ
            if not first_frame_success and self.status == StreamStatus.STARTING:
                self.status = StreamStatus.ERROR
                if not self.error_message:
                    self.error_message = "ì²« í”„ë ˆì„ ìˆ˜ì‹  ì „ ì¢…ë£Œë¨"
    
    def _apply_blur(self, frame: np.ndarray, box: tuple) -> np.ndarray:
        """ìµëª…í™” ì²˜ë¦¬ (ë¸”ëŸ¬/í”½ì…€í™”/ëª¨ìì´í¬ ë“±)"""
        h, w = frame.shape[:2]
        x1, y1, x2, y2 = box
        
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        if x2 <= x1 or y2 <= y1:
            return frame
        
        method = self.blur_settings.anonymize_method
        face_region = frame[y1:y2, x1:x2]
        face_h, face_w = face_region.shape[:2]
        
        if method == "blur":
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (ëŠë¦¼, ë¶€ë“œëŸ¬ì›€)
            blur_strength = self.blur_settings.blur_strength
            if blur_strength % 2 == 0:
                blur_strength += 1
            processed = cv2.GaussianBlur(face_region, (blur_strength, blur_strength), 0)
            
        elif method == "pixelate":
            # í”½ì…€í™” (ë¹ ë¦„, íš¨ìœ¨ì ) âš¡
            pixel_size = self.blur_settings.pixelate_size
            small_w = max(1, face_w // pixel_size)
            small_h = max(1, face_h // pixel_size)
            # ì‘ê²Œ ì¶•ì†Œ
            small = cv2.resize(face_region, (small_w, small_h), interpolation=cv2.INTER_LINEAR)
            # ì›ë˜ í¬ê¸°ë¡œ í™•ëŒ€
            processed = cv2.resize(small, (face_w, face_h), interpolation=cv2.INTER_NEAREST)
            
        elif method == "mosaic":
            # ëª¨ìì´í¬ (í”½ì…€í™”ì™€ ìœ ì‚¬, ë¹ ë¦„) âš¡
            pixel_size = self.blur_settings.pixelate_size
            small_w = max(1, face_w // pixel_size)
            small_h = max(1, face_h // pixel_size)
            # ì‘ê²Œ ì¶•ì†Œ
            small = cv2.resize(face_region, (small_w, small_h), interpolation=cv2.INTER_AREA)
            # ì›ë˜ í¬ê¸°ë¡œ í™•ëŒ€
            processed = cv2.resize(small, (face_w, face_h), interpolation=cv2.INTER_NEAREST)
            
        elif method == "black":
            # ê²€ì€ ë°•ìŠ¤ (ê°€ì¥ ë¹ ë¦„)
            processed = np.zeros_like(face_region)
            
        elif method == "solid":
            # ë‹¨ìƒ‰ ì±„ìš°ê¸° (ë¹ ë¦„)
            # í‰ê·  ìƒ‰ìƒìœ¼ë¡œ ì±„ìš°ê¸°
            avg_color = np.mean(face_region, axis=(0, 1)).astype(np.uint8)
            processed = np.full_like(face_region, avg_color)
            
        else:
            # ê¸°ë³¸ê°’: í”½ì…€í™”
            pixel_size = self.blur_settings.pixelate_size
            small_w = max(1, face_w // pixel_size)
            small_h = max(1, face_h // pixel_size)
            small = cv2.resize(face_region, (small_w, small_h), interpolation=cv2.INTER_LINEAR)
            processed = cv2.resize(small, (face_w, face_h), interpolation=cv2.INTER_NEAREST)
        
        frame[y1:y2, x1:x2] = processed
        return frame
    
    def _start_ffmpeg(self, width: int, height: int):
        """FFmpeg ì¶œë ¥ ì‹œì‘ (ì§€ì—° ìµœì†Œí™” + í™”ì§ˆ ê°œì„  ìµœì í™”)"""
        # ì¸ì½”ë”© ì„¤ì •: CRF ê¸°ë°˜ ê°€ë³€ ë¹„íŠ¸ë ˆì´íŠ¸ (í™”ì§ˆ ìš°ì„ ) ë˜ëŠ” ê³ ì • ë¹„íŠ¸ë ˆì´íŠ¸
        use_crf = settings.output_crf is not None and settings.output_crf > 0
        
        cmd = [
            settings.ffmpeg_path,
            '-y',
            '-f', 'rawvideo',
            '-vcodec', 'rawvideo',
            '-pix_fmt', 'bgr24',
            '-s', f'{width}x{height}',
            '-r', str(settings.output_fps),
            '-i', '-',
            '-c:v', settings.output_codec,  # libx264 ë˜ëŠ” í•˜ë“œì›¨ì–´ ì¸ì½”ë”
            '-preset', settings.output_preset,  # veryfast (í™”ì§ˆê³¼ ì†ë„ ê· í˜•)
            '-tune', 'zerolatency',  # ì§€ì—° ìµœì†Œí™”
        ]
        
        # ë¹„íŠ¸ë ˆì´íŠ¸ ë˜ëŠ” CRF ì„¤ì •
        if use_crf:
            cmd.extend(['-crf', str(settings.output_crf)])  # ê°€ë³€ ë¹„íŠ¸ë ˆì´íŠ¸ (í™”ì§ˆ ìš°ì„ )
        else:
            # ë¹„íŠ¸ë ˆì´íŠ¸ íŒŒì‹± (ì˜ˆ: "4000k" -> 4000, "6M" -> 6000)
            bitrate_str = settings.output_bitrate.upper()
            if bitrate_str.endswith('K'):
                bitrate_val = int(bitrate_str[:-1])
            elif bitrate_str.endswith('M'):
                bitrate_val = int(bitrate_str[:-1]) * 1000
            else:
                bitrate_val = int(bitrate_str)
            
            cmd.extend([
                '-b:v', settings.output_bitrate,
                '-maxrate', settings.output_bitrate,
                '-bufsize', f'{bitrate_val * 2}k',  # ë²„í¼ í¬ê¸° = ë¹„íŠ¸ë ˆì´íŠ¸ * 2
            ])
        
        cmd.extend([
            '-pix_fmt', 'yuv420p',
            '-g', str(settings.output_fps),  # GOP í¬ê¸° = fps (í‚¤í”„ë ˆì„ ê°„ê²©)
            '-x264-params', f'keyint={settings.output_fps}:min-keyint={settings.output_fps}:scenecut=0',  # í‚¤í”„ë ˆì„ ìµœì í™”
            '-fflags', 'nobuffer',  # ì…ë ¥ ë²„í¼ ìµœì†Œí™”
            '-flags', 'low_delay',  # ë‚®ì€ ì§€ì—° í”Œë˜ê·¸
            '-strict', 'experimental',
            '-f', 'rtsp',
            '-rtsp_transport', 'tcp',
            '-rtsp_flags', 'prefer_tcp',  # TCP ìš°ì„  ì‚¬ìš©
            '-muxdelay', '0',  # ë©€í‹°í”Œë ‰ì„œ ì§€ì—° ì œê±°
            self.output_url
        ])
        
        # ì—°ê²° ì‹œë„ ë¡œê·¸
        print(f"[{self.stream_id}] ğŸ”— Flashphoner ì—°ê²° ì‹œë„: {self.output_url}")
        
        # FFmpeg ì‹¤í–‰ (ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸ì„ ìœ„í•´ stderrë¥¼ PIPEë¡œ ì„¤ì •)
        self._ffmpeg_process = subprocess.Popen(
            cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.PIPE,  # ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸ìš©
            bufsize=0,  # ë²„í¼ë§ ì—†ìŒ
            start_new_session=True  # ë³„ë„ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì—ì„œ ì‹¤í–‰ (ì„œë²„ ì¢…ë£Œ ë°©ì§€)
        )
        self._ffmpeg_stderr = ""
        
        # stderr ì½ê¸° ìŠ¤ë ˆë“œ ì‹œì‘ (ì—ëŸ¬ ë©”ì‹œì§€ ìˆ˜ì§‘)
        def read_stderr():
            try:
                if self._ffmpeg_process and self._ffmpeg_process.stderr:
                    while True:
                        line = self._ffmpeg_process.stderr.readline()
                        if not line:
                            break
                        line_str = line.decode('utf-8', errors='ignore').strip()
                        if line_str:
                            self._ffmpeg_stderr += line_str + "\n"
                            # ëª¨ë“  RTSP ê´€ë ¨ ë©”ì‹œì§€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                            line_lower = line_str.lower()
                            if 'rtsp' in line_lower or 'connection' in line_lower or 'streaming' in line_lower:
                                print(f"[{self.stream_id}] ğŸ“¡ FFmpeg RTSP: {line_str}")
                            
                            # ì—ëŸ¬ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¶œë ¥
                            if any(keyword in line_lower for keyword in ['error', 'failed', 'connection refused', 'timeout', 'unable', 'denied', 'forbidden', 'connection reset', 'cannot', 'unable to']):
                                print(f"[{self.stream_id}] âš ï¸ FFmpeg ì—ëŸ¬: {line_str}")
            except Exception:
                pass
        
        stderr_thread = threading.Thread(target=read_stderr, daemon=True)
        stderr_thread.start()
    
    def _check_ffmpeg_alive(self) -> bool:
        """FFmpeg í”„ë¡œì„¸ìŠ¤ ìƒì¡´ í™•ì¸"""
        if self._ffmpeg_process is None:
            return False
        
        ret = self._ffmpeg_process.poll()
        if ret is not None:
            # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨ - stderr ì½ê¸° ì‹œë„
            error_msg = self._get_ffmpeg_error()
            print(f"[{self.stream_id}] FFmpeg ì¢…ë£Œ (code={ret})")
            if error_msg:
                print(f"[{self.stream_id}] FFmpeg ì—ëŸ¬: {error_msg[:500]}")
            return False
        return True
    
    def _get_ffmpeg_error(self) -> str:
        """FFmpeg stderrì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ ì½ê¸°"""
        if self._ffmpeg_process is None or self._ffmpeg_process.stderr is None:
            return self._ffmpeg_stderr or ""
        
        try:
            # Unix: selectë¡œ non-blocking ì½ê¸°
            if hasattr(select, 'select') and hasattr(select.select, '__call__'):
                try:
                    ready, _, _ = select.select([self._ffmpeg_process.stderr], [], [], 0.1)
                    if ready:
                        error = self._ffmpeg_process.stderr.read(2000)
                        if error:
                            error_str = error.decode('utf-8', errors='ignore') if isinstance(error, bytes) else error
                            if not self._ffmpeg_stderr:
                                self._ffmpeg_stderr = ""
                            self._ffmpeg_stderr += error_str
                            return self._ffmpeg_stderr
                except (OSError, ValueError):
                    # Windowsì—ì„œëŠ” selectê°€ íŒŒì´í”„ì—ì„œ ì‘ë™í•˜ì§€ ì•ŠìŒ
                    pass
        except:
            pass
        
        # Windows ë˜ëŠ” select ì‹¤íŒ¨ ì‹œ: ì´ë¯¸ ì½ì€ ë‚´ìš©ì´ ìˆìœ¼ë©´ ë°˜í™˜
        return self._ffmpeg_stderr or ""
    
    def _restart_ffmpeg(self, width: int, height: int):
        """FFmpeg ì¬ì‹œì‘ (ë¹ ë¥¸ ì¢…ë£Œ)"""
        if self._ffmpeg_process:
            try:
                # stdin ë‹«ê¸°
                if self._ffmpeg_process.stdin:
                    try:
                        self._ffmpeg_process.stdin.close()
                    except:
                        pass
                # ì¦‰ì‹œ kill (wait ì—†ìŒ)
                self._ffmpeg_process.kill()
            except:
                pass
        self._start_ffmpeg(width, height)
        print(f"[{self.stream_id}] FFmpeg ì¬ì‹œì‘ë¨")
    
    def _cleanup_fast(self):
        """ë¹ ë¥¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (íƒ€ì„ì•„ì›ƒ ìµœì†Œí™”)"""
        import os
        
        # VideoCapture ì •ë¦¬
        if self._cap:
            try:
                self._cap.release()
            except:
                pass
            self._cap = None
        
        # FFmpeg ì •ë¦¬ (ì¦‰ì‹œ kill, wait ì—†ìŒ)
        if self._ffmpeg_process:
            try:
                # stdin ë‹«ê¸°
                if self._ffmpeg_process.stdin:
                    try:
                        self._ffmpeg_process.stdin.close()
                    except:
                        pass
                
                # í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ ì¢…ë£Œ (Unix) - ë³„ë„ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì•ˆì „
                if hasattr(os, 'killpg'):
                    try:
                        pgid = os.getpgid(self._ffmpeg_process.pid)
                        # ì„œë²„ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ê³¼ ë‹¤ë¥¼ ë•Œë§Œ killpg ì‚¬ìš© (ì•ˆì „ì„± ê°•í™”)
                        if pgid != os.getpgid(os.getpid()):
                            os.killpg(pgid, 9)  # SIGKILL
                    except (OSError, ProcessLookupError):
                        pass
                
                # ì¦‰ì‹œ kill (wait ì—†ìŒ)
                try:
                    self._ffmpeg_process.kill()
                except:
                    pass
            except Exception as e:
                print(f"[{self.stream_id}] FFmpeg ì •ë¦¬ ì˜¤ë¥˜: {e}")
            finally:
                self._ffmpeg_process = None
        
        self._tracker.reset()
    
    def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ê°•í™”) - _process_loopì—ì„œ ì‚¬ìš©"""
        import os
        
        # VideoCapture ì •ë¦¬
        if self._cap:
            try:
                self._cap.release()
            except:
                pass
            self._cap = None
        
        # FFmpeg ì •ë¦¬ (ê°•ì œ ì¢…ë£Œ í¬í•¨)
        if self._ffmpeg_process:
            try:
                # stdin ë‹«ê¸°
                if self._ffmpeg_process.stdin:
                    try:
                        self._ffmpeg_process.stdin.close()
                    except:
                        pass
                
                # í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ ì¢…ë£Œ (Unix) - ë³„ë„ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì•ˆì „
                if hasattr(os, 'killpg'):
                    try:
                        pgid = os.getpgid(self._ffmpeg_process.pid)
                        # ì„œë²„ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ê³¼ ë‹¤ë¥¼ ë•Œë§Œ killpg ì‚¬ìš© (ì•ˆì „ì„± ê°•í™”)
                        if pgid != os.getpgid(os.getpid()):
                            os.killpg(pgid, 15)  # SIGTERM
                    except (OSError, ProcessLookupError):
                        pass
                
                # ì¢…ë£Œ ëŒ€ê¸°
                self._ffmpeg_process.terminate()
                try:
                    self._ffmpeg_process.wait(timeout=1)
                except:
                    self._ffmpeg_process.kill()
                    try:
                        self._ffmpeg_process.wait(timeout=0.5)
                    except:
                        pass
            except Exception as e:
                print(f"[{self.stream_id}] FFmpeg ì •ë¦¬ ì˜¤ë¥˜: {e}")
            self._ffmpeg_process = None
        
        self._tracker.reset()